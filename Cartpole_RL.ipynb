{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning made easier(CartPole game Example)\n",
    "CartPole, also known as inverted pendulum, is a game in which you try to balance the pole as long as possible. It is assumed that at the tip of the pole, there is an object which makes it unstable and very likely to fall over. The goal of this task is to move the cart left and right so that the pole can stand (within a certain angle) as long as possible.\n",
    "\n",
    "In this notebook, we will look at reinforcement learning, a field in artificial intelligence where the AI explores the environment all by itself by playing the game many many times until it learns the right way to play the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:cade137f-f5b8-41cd-add3-7310aa8349bb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /home/oyogo/.local/lib/python3.8/site-packages (0.15.3)\n",
      "Requirement already satisfied: six in /home/oyogo/.local/lib/python3.8/site-packages (from gym) (1.15.0)\n",
      "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /home/oyogo/.local/lib/python3.8/site-packages (from gym) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/oyogo/.local/lib/python3.8/site-packages (from gym) (1.19.5)\n",
      "Requirement already satisfied: scipy in /home/oyogo/.local/lib/python3.8/site-packages (from gym) (1.6.2)\n",
      "Requirement already satisfied: cloudpickle~=1.2.0 in /home/oyogo/.local/lib/python3.8/site-packages (from gym) (1.2.2)\n",
      "Requirement already satisfied: future in /home/oyogo/anaconda3/lib/python3.8/site-packages (from pyglet<=1.3.2,>=1.2.0->gym) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "#Installing the gym Package\n",
    "!pip install gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /home/oyogo/.local/lib/python3.8/site-packages (0.15.3)\n",
      "Requirement already satisfied: six in /home/oyogo/.local/lib/python3.8/site-packages (from gym) (1.15.0)\n",
      "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /home/oyogo/.local/lib/python3.8/site-packages (from gym) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/oyogo/.local/lib/python3.8/site-packages (from gym) (1.19.5)\n",
      "Requirement already satisfied: scipy in /home/oyogo/.local/lib/python3.8/site-packages (from gym) (1.6.2)\n",
      "Requirement already satisfied: cloudpickle~=1.2.0 in /home/oyogo/.local/lib/python3.8/site-packages (from gym) (1.2.2)\n",
      "Requirement already satisfied: future in /home/oyogo/anaconda3/lib/python3.8/site-packages (from pyglet<=1.3.2,>=1.2.0->gym) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "#Installing the gym Package\n",
    "!pip install gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the gym package \n",
    "import gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Cartpole environment\n",
    "e = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00458956, -0.00997421,  0.0388211 , -0.0196665 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reseting the environment an obtaining the first observation\n",
    "obs=e.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returns the possible actions that the agent can take\n",
    "# The action_space in this case is discrete, which means it is either 0 or 1\n",
    "e.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(4,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return the observation space, and in this case it is of a BOX( n-dimesnional tensor), [inf, inf]\n",
    "e.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00439007, -0.20563078,  0.03842777,  0.28500776]), 1.0, False, {})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we performed action 0, which is moving the pole to the left\n",
    "e.step(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## We got the tuple of four elements:\n",
    "• A new observation, which is a new vector of four numbers\n",
    "\n",
    "• A reward of 1.0\n",
    "\n",
    "• The done flag with value False , which means that the episode is not over yet\n",
    "and we are more or less okay\n",
    "\n",
    "• Extra information about the environment, which is an empty dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the sample() of the space class in the action_space and observation_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.9186893e-01, -2.1650322e+38,  2.3133039e-02,  1.2271323e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.2680448e-01, -1.8839460e+38,  3.6352718e-01,  1.4929361e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method returned a random sample from the underlying space which is discrete for the actions, and for the observations it is random four vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartpole Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode done in 1 steps, total reward 1.00\n",
      "Episode done in 2 steps, total reward 2.00\n",
      "Episode done in 3 steps, total reward 3.00\n",
      "Episode done in 4 steps, total reward 4.00\n",
      "Episode done in 5 steps, total reward 5.00\n",
      "Episode done in 6 steps, total reward 6.00\n",
      "Episode done in 7 steps, total reward 7.00\n",
      "Episode done in 8 steps, total reward 8.00\n",
      "Episode done in 9 steps, total reward 9.00\n",
      "Episode done in 10 steps, total reward 10.00\n",
      "Episode done in 11 steps, total reward 11.00\n",
      "Episode done in 12 steps, total reward 12.00\n",
      "Episode done in 13 steps, total reward 13.00\n",
      "Episode done in 14 steps, total reward 14.00\n",
      "Episode done in 15 steps, total reward 15.00\n",
      "Episode done in 16 steps, total reward 16.00\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    env=gym.make(\"CartPole-v0\")\n",
    "    # Gym has a wrapper like class which is called Monitor. It is used to monitor the performance of the Agent, \n",
    "    # you can record the performance in form of a video, but you need to first install ffmpg.\n",
    "    env = gym.wrappers.Monitor(env, \"recording\")\n",
    "    total_reward = 0.0\n",
    "    total_steps= 0\n",
    "    obs=env.reset()\n",
    "    \n",
    "    while True:\n",
    "        action= env.action_space.sample()\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        total_reward +=reward\n",
    "        total_steps += 1\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "        print(\"Episode done in %d steps, total reward %.2f\" % (\n",
    "        total_steps, total_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this loop, I have sampled a random action, then asked the environment to execute\n",
    "it and return to us the next observation ( obs ), the reward , and the done flag. If the\n",
    "episode is over, we stop the loop and show how many steps we have taken and\n",
    "how much reward has been accumulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
